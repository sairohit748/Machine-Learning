{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\STUDY\\SEM-4\\ML\\Assignment-1\n"
     ]
    }
   ],
   "source": [
    "cd D:\\STUDY\\SEM-4\\ML\\Assignment-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('student-mat.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x266d1b7dcc0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x266d1b51710>,\n",
       "  <matplotlib.lines.Line2D at 0x266d1b51b38>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x266d01093c8>],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x266d1b51f60>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x266d1b7de10>,\n",
       "  <matplotlib.lines.Line2D at 0x266d1b512e8>]}"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x266d1c2da20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plot a line, implicitly creating a subplot(111)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.boxplot(data['famrel'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "famrel <- 2 and below\n",
    "freetime<-2 and below\n",
    "Dalc <- 4 and above\n",
    "absences <- 25 and above\n",
    "**failures <- 0 and above**\n",
    "studytime <- 4 and above\n",
    "traveltime <- 4 and above\n",
    "Fedu <- 0 and below\n",
    "age <- 22 and above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data[~((data['famrel']<=2))]\n",
    "data = data[~((data['freetime']<=2))]\n",
    "data = data[~((data['Dalc']>=4))]\n",
    "data = data[~((data['absences']>=25))]\n",
    "data = data[~((data['studytime']>=4))]\n",
    "data = data[~((data['traveltime']>=4))]\n",
    "data = data[~((data['Fedu']==0))]\n",
    "data = data[~((data['age']>=22))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 33)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['age','traveltime','studytime','failures','famrel','freetime','goout','Dalc','Walc','health','absences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c:\n",
    "    data[i]= (data[i]-(data[i].mean()*np.ones(data.shape[0])))/(data[i].max()-data[i].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = pd.concat([data['failures'],data['absences'],pd.get_dummies(data['romantic'],drop_first=True),data['freetime'],data['goout'],data['age']],axis =1)\n",
    "xdata_model = sm.add_constant(xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split ( xdata_model, data['G3'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>G3</td>        <th>  R-squared:         </th> <td>   0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Sep 2018</td> <th>  Prob (F-statistic):</th> <td>6.40e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:32:46</td>     <th>  Log-Likelihood:    </th> <td> -475.91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   168</td>      <th>  AIC:               </th> <td>   965.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   161</td>      <th>  BIC:               </th> <td>   987.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>   10.6465</td> <td>    0.386</td> <td>   27.591</td> <td> 0.000</td> <td>    9.884</td> <td>   11.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>failures</th> <td>   -7.6359</td> <td>    1.251</td> <td>   -6.103</td> <td> 0.000</td> <td>  -10.107</td> <td>   -5.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>absences</th> <td>    3.3121</td> <td>    1.441</td> <td>    2.298</td> <td> 0.023</td> <td>    0.466</td> <td>    6.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yes</th>      <td>   -1.7559</td> <td>    0.733</td> <td>   -2.395</td> <td> 0.018</td> <td>   -3.204</td> <td>   -0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>freetime</th> <td>    3.2715</td> <td>    0.993</td> <td>    3.294</td> <td> 0.001</td> <td>    1.310</td> <td>    5.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>goout</th>    <td>   -2.6794</td> <td>    1.219</td> <td>   -2.198</td> <td> 0.029</td> <td>   -5.086</td> <td>   -0.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>      <td>   -2.3883</td> <td>    1.538</td> <td>   -1.553</td> <td> 0.122</td> <td>   -5.426</td> <td>    0.649</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.241</td> <th>  Durbin-Watson:     </th> <td>   1.909</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.044</td> <th>  Jarque-Bera (JB):  </th> <td>   6.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.465</td> <th>  Prob(JB):          </th> <td>  0.0473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.080</td> <th>  Cond. No.          </th> <td>    5.14</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     G3   R-squared:                       0.305\n",
       "Model:                            OLS   Adj. R-squared:                  0.279\n",
       "Method:                 Least Squares   F-statistic:                     11.77\n",
       "Date:                Mon, 17 Sep 2018   Prob (F-statistic):           6.40e-11\n",
       "Time:                        14:32:46   Log-Likelihood:                -475.91\n",
       "No. Observations:                 168   AIC:                             965.8\n",
       "Df Residuals:                     161   BIC:                             987.7\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         10.6465      0.386     27.591      0.000       9.884      11.408\n",
       "failures      -7.6359      1.251     -6.103      0.000     -10.107      -5.165\n",
       "absences       3.3121      1.441      2.298      0.023       0.466       6.158\n",
       "yes           -1.7559      0.733     -2.395      0.018      -3.204      -0.308\n",
       "freetime       3.2715      0.993      3.294      0.001       1.310       5.233\n",
       "goout         -2.6794      1.219     -2.198      0.029      -5.086      -0.273\n",
       "age           -2.3883      1.538     -1.553      0.122      -5.426       0.649\n",
       "==============================================================================\n",
       "Omnibus:                        6.241   Durbin-Watson:                   1.909\n",
       "Prob(Omnibus):                  0.044   Jarque-Bera (JB):                6.104\n",
       "Skew:                          -0.465   Prob(JB):                       0.0473\n",
       "Kurtosis:                       3.080   Cond. No.                         5.14\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = smf.OLS(y_train,X_train).fit()\n",
    "q.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradientDescent(x, y, theta, alpha, m, numIterations):\n",
    "    xTrans = x.transpose()\n",
    "    lst = [1,2]\n",
    "    costly = [1,2]\n",
    "    for k in range(len(alpha)):\n",
    "        for i in range(0, numIterations):\n",
    "            hypothesis = np.dot(x, theta)\n",
    "            loss = hypothesis - y\n",
    "            cost = np.sum(loss ** 2) / (2 * m)\n",
    "            gradient = np.dot(xTrans, loss) / m\n",
    "            # update\n",
    "            theta = theta - alpha[k] * gradient   \n",
    "        lst[k] = theta\n",
    "        costly[k] = cost    \n",
    "    return lst,costly        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([array([10.64621089, -7.62738489,  3.28722723, -1.7566284 ,  3.27201606,\n",
      "       -2.68078622, -2.37645627]), array([10.64646869, -7.63594428,  3.31207782, -1.75592717,  3.27145057,\n",
      "       -2.67944722, -2.38825761])], [8.453379774567972, 8.453359261009663])\n"
     ]
    }
   ],
   "source": [
    "x = X_train\n",
    "y = y_train\n",
    "m,n = np.shape(x)\n",
    "numIterations= 100000\n",
    "alpha = [0.001,0.01]\n",
    "theta = np.ones(n)\n",
    "theta = gradientDescent(x, y, theta, alpha, m, numIterations)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Learning Rate and Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, theta, alpha, m, numIterations):\n",
    "    xTrans = x.transpose()\n",
    "    lst = [1,2,3]\n",
    "    iteration = [1,2,3]\n",
    "    for k in range(len(alpha)):\n",
    "        prev_cost = 0\n",
    "        for i in range(0, numIterations):\n",
    "            hypothesis = np.dot(x, theta)\n",
    "            loss = hypothesis - y\n",
    "            cost = np.sum(loss ** 2) / (2 * m)\n",
    "            if abs(cost-prev_cost) <= 0.000001:\n",
    "                print(\"Iteration %d | Cost: %f\" % (i, cost))\n",
    "                break\n",
    "            else:\n",
    "                prev_cost = cost\n",
    "            gradient = np.dot(xTrans, loss) / m\n",
    "            # update\n",
    "            theta = theta - alpha[k] * gradient   \n",
    "        lst[k] = theta\n",
    "        iteration[k] = i\n",
    "    return lst,iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45611 | Cost: 8.461533\n",
      "Iteration 1891 | Cost: 8.454242\n",
      "([array([10.64352737, -7.28827555,  2.97384805, -1.7843249 ,  3.16359965,\n",
      "       -2.64958012, -2.22008841]), array([10.64499051, -7.53933116,  3.17544565, -1.76335365,  3.25133632,\n",
      "       -2.67965074, -2.32586007])], [45611, 1891])\n"
     ]
    }
   ],
   "source": [
    "x = X_train\n",
    "y = y_train\n",
    "m,n = np.shape(x)\n",
    "numIterations= 100000\n",
    "alpha = [0.001,0.01,0.05]\n",
    "theta = np.ones(n)\n",
    "result = gradientDescent(x, y, theta, alpha, m, numIterations)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.permutation(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.09186677, 17.38335254])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "holding_place = np.zeros((n,2))\n",
    "for i in range(n):\n",
    "    test = sample[int(data.shape[0]*i/n):int(data.shape[0]*(i+1)/n)]\n",
    "    train_u = sample[:int(data.shape[0]*i/n)]\n",
    "    train_l = sample[int(data.shape[0]*(i+1)/n):]\n",
    "    train = np.concatenate([train_l,train_u])\n",
    "    \n",
    "    q = smf.OLS(data['G3'].iloc[train],xdata_model.iloc[train]).fit()\n",
    "    \n",
    "    yp_train= q.predict(xdata_model.iloc[train])\n",
    "    MSE_train=mean_squared_error(data['G3'].iloc[train], yp_train)\n",
    "    \n",
    "    yp_test= q.predict(xdata_model.iloc[test])\n",
    "    MSE_test=mean_squared_error(data['G3'].iloc[test], yp_test)\n",
    "    \n",
    "    holding_place[i,0] = MSE_train\n",
    "    holding_place[i,1] = MSE_test\n",
    "holding_place.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['G3'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "4      0\n",
       "5      1\n",
       "6      1\n",
       "9      1\n",
       "10     0\n",
       "12     1\n",
       "13     1\n",
       "14     1\n",
       "15     1\n",
       "17     0\n",
       "18     0\n",
       "20     1\n",
       "21     1\n",
       "22     1\n",
       "23     1\n",
       "24     0\n",
       "28     1\n",
       "30     1\n",
       "31     1\n",
       "32     1\n",
       "33     1\n",
       "34     1\n",
       "35     0\n",
       "36     1\n",
       "38     1\n",
       "39     1\n",
       "41     1\n",
       "      ..\n",
       "348    1\n",
       "350    0\n",
       "351    1\n",
       "352    0\n",
       "353    0\n",
       "354    1\n",
       "355    0\n",
       "356    1\n",
       "358    0\n",
       "359    1\n",
       "360    1\n",
       "361    1\n",
       "362    0\n",
       "365    0\n",
       "371    1\n",
       "372    1\n",
       "373    0\n",
       "374    1\n",
       "376    1\n",
       "377    0\n",
       "379    0\n",
       "381    0\n",
       "382    0\n",
       "383    0\n",
       "385    0\n",
       "386    0\n",
       "387    0\n",
       "388    0\n",
       "392    0\n",
       "393    0\n",
       "Name: dep, Length: 251, dtype: int32"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dep']= (data['G3']>=11).astype(int)\n",
    "data['dep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>dep</td>       <th>  No. Observations:  </th>  <td>   251</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   244</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>       <td>Binomial</td>     <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>        <td>logit</td>      <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -151.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 17 Sep 2018</td> <th>  Deviance:          </th> <td>  302.75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>17:53:54</td>     <th>  Pearson chi2:      </th>  <td>  250.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>5</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    0.0329</td> <td>    0.170</td> <td>    0.193</td> <td> 0.847</td> <td>   -0.301</td> <td>    0.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>romantic[T.yes]</th> <td>   -0.2412</td> <td>    0.309</td> <td>   -0.780</td> <td> 0.435</td> <td>   -0.847</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>failures</th>        <td>   -3.6581</td> <td>    0.914</td> <td>   -4.004</td> <td> 0.000</td> <td>   -5.449</td> <td>   -1.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>absences</th>        <td>   -0.1242</td> <td>    0.662</td> <td>   -0.188</td> <td> 0.851</td> <td>   -1.422</td> <td>    1.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>freetime</th>        <td>    1.3695</td> <td>    0.451</td> <td>    3.036</td> <td> 0.002</td> <td>    0.485</td> <td>    2.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>goout</th>           <td>   -1.6067</td> <td>    0.567</td> <td>   -2.834</td> <td> 0.005</td> <td>   -2.718</td> <td>   -0.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>             <td>   -0.4169</td> <td>    0.734</td> <td>   -0.568</td> <td> 0.570</td> <td>   -1.856</td> <td>    1.022</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                    dep   No. Observations:                  251\n",
       "Model:                            GLM   Df Residuals:                      244\n",
       "Model Family:                Binomial   Df Model:                            6\n",
       "Link Function:                  logit   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -151.38\n",
       "Date:                Mon, 17 Sep 2018   Deviance:                       302.75\n",
       "Time:                        17:53:54   Pearson chi2:                     250.\n",
       "No. Iterations:                     5                                         \n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           0.0329      0.170      0.193      0.847      -0.301       0.367\n",
       "romantic[T.yes]    -0.2412      0.309     -0.780      0.435      -0.847       0.365\n",
       "failures           -3.6581      0.914     -4.004      0.000      -5.449      -1.868\n",
       "absences           -0.1242      0.662     -0.188      0.851      -1.422       1.174\n",
       "freetime            1.3695      0.451      3.036      0.002       0.485       2.254\n",
       "goout              -1.6067      0.567     -2.834      0.005      -2.718      -0.496\n",
       "age                -0.4169      0.734     -0.568      0.570      -1.856       1.022\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = smf.glm('dep~failures+absences+romantic+freetime+goout+age',family=sm.families.Binomial(),data = data).fit()\n",
    "a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12947298, 0.01188166, 0.01457309, ..., 0.02376858, 0.02762848,\n",
       "        0.0211699 ],\n",
       "       [0.09835254, 0.01071159, 0.01331033, ..., 0.02774174, 0.02566631,\n",
       "        0.02308263],\n",
       "       [0.11195799, 0.01962179, 0.01845084, ..., 0.01352666, 0.02025387,\n",
       "        0.018472  ],\n",
       "       ...,\n",
       "       [0.08070474, 0.01497674, 0.01996946, ..., 0.02112943, 0.04471299,\n",
       "        0.03161606],\n",
       "       [0.09132211, 0.01407107, 0.01530084, ..., 0.02212425, 0.0268637 ,\n",
       "        0.02216149],\n",
       "       [0.24803029, 0.02456806, 0.04060163, ..., 0.01051179, 0.01562609,\n",
       "        0.014519  ]])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = lr.predict_proba(X_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
